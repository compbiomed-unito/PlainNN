{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d90d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Training and testing of the model\n",
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import torch\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from models import init_model_dict, init_optim\n",
    "from utils import one_hot_tensor, cal_sample_weight, gen_adj_mat_tensor, gen_test_adj_mat_tensor, cal_adj_mat_parameter\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "seed_list = []\n",
    "\n",
    "def prepare_trte_data(data_folder, view_list,i):\n",
    "    num_view = len(view_list)\n",
    "    labels_tr = np.loadtxt(os.path.join(data_folder, \"labels_tr.csv\"), delimiter=',')\n",
    "    labels_te = np.loadtxt(os.path.join(data_folder, \"labels_te.csv\"), delimiter=',')\n",
    "    labels_tr = labels_tr.astype(int)\n",
    "    labels_te = labels_te.astype(int)\n",
    "    data_tr_list = []\n",
    "    data_te_list = []\n",
    "    for i in view_list:\n",
    "        data_tr_list.append(np.loadtxt(os.path.join(data_folder, str(i)+\"_tr.csv\"), delimiter=','))\n",
    "        data_te_list.append(np.loadtxt(os.path.join(data_folder, str(i)+\"_te.csv\"), delimiter=','))\n",
    "    num_tr = data_tr_list[0].shape[0]\n",
    "    num_te = data_te_list[0].shape[0]\n",
    "    data_mat_list = []\n",
    "    for i in range(num_view):\n",
    "        data_mat_list.append(np.concatenate((data_tr_list[i], data_te_list[i]), axis=0))\n",
    "    data_tensor_list = []\n",
    "    for i in range(len(data_mat_list)):\n",
    "        data_tensor_list.append(torch.FloatTensor(data_mat_list[i]))\n",
    "        if cuda:\n",
    "            data_tensor_list[i] = data_tensor_list[i].cuda()\n",
    "    idx_dict = {}\n",
    "    idx_origin = {}\n",
    "    ind_list = list(range(num_tr+num_te))\n",
    "########################## Random Splitting and Shuffling #####################################\n",
    "    seed = random.randint(1,100000)\n",
    "    seed_list.append(seed)\n",
    "    random.Random(seed).shuffle(ind_list)  \n",
    "###############################################################################################\n",
    "    idx_origin[\"tr\"] = list(range(num_tr))\n",
    "    idx_origin[\"te\"] = list(range(num_tr, (num_tr+num_te)))\n",
    "    idx_dict[\"tr\"] = ind_list[0:num_tr]\n",
    "    idx_dict[\"te\"] = ind_list[num_tr:]\n",
    "    data_train_list = []\n",
    "    data_all_list = []\n",
    "    for i in range(len(data_tensor_list)):\n",
    "        data_train_list.append(data_tensor_list[i][idx_dict[\"tr\"]].clone())\n",
    "        data_all_list.append(torch.cat((data_tensor_list[i][idx_dict[\"tr\"]].clone(),\n",
    "                                       data_tensor_list[i][idx_dict[\"te\"]].clone()),0)) \n",
    "    labels = np.concatenate((labels_tr, labels_te))\n",
    "    labels = labels[ind_list]\n",
    "    idx_dict = idx_origin\n",
    "    return data_train_list, data_all_list, idx_dict, labels\n",
    "\n",
    "\n",
    "def gen_trte_adj_mat(data_tr_list, data_trte_list, trte_idx, adj_parameter):\n",
    "    adj_metric = \"cosine\" # cosine distance\n",
    "    adj_train_list = []\n",
    "    adj_test_list = []\n",
    "    for i in range(len(data_tr_list)):\n",
    "        adj_parameter_adaptive = cal_adj_mat_parameter(adj_parameter, data_tr_list[i], adj_metric)\n",
    "        adj_train_list.append(gen_adj_mat_tensor(data_tr_list[i], adj_parameter_adaptive, adj_metric))\n",
    "        adj_test_list.append(gen_test_adj_mat_tensor(data_trte_list[i], trte_idx, adj_parameter_adaptive, adj_metric))\n",
    "    \n",
    "    return adj_train_list, adj_test_list\n",
    "\n",
    "\n",
    "def train_epoch(data_list, adj_list, label, one_hot_label, sample_weight, model_dict, optim_dict, train_VCDN=True):\n",
    "    loss_dict = {}\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "    for m in model_dict:\n",
    "        model_dict[m].train()    \n",
    "    num_view = len(data_list)\n",
    "    for i in range(num_view):\n",
    "        optim_dict[\"C{:}\".format(i+1)].zero_grad()\n",
    "        ci_loss = 0\n",
    "        ci = model_dict[\"C{:}\".format(i+1)](model_dict[\"E{:}\".format(i+1)](data_list[i],adj_list[i]))\n",
    "        ci_loss = torch.mean(torch.mul(criterion(ci, label),sample_weight))\n",
    "        ci_loss.backward()\n",
    "        optim_dict[\"C{:}\".format(i+1)].step()\n",
    "        loss_dict[\"C{:}\".format(i+1)] = ci_loss.detach().cpu().numpy().item()\n",
    "    if train_VCDN and num_view >= 2:\n",
    "        optim_dict[\"C\"].zero_grad()\n",
    "        c_loss = 0\n",
    "        ci_list = []\n",
    "        for i in range(num_view):\n",
    "            ci_list.append(model_dict[\"C{:}\".format(i+1)](model_dict[\"E{:}\".format(i+1)](data_list[i],adj_list[i])))\n",
    "        c = model_dict[\"C\"](ci_list)    \n",
    "        c_loss = torch.mean(torch.mul(criterion(c, label),sample_weight))\n",
    "        c_loss.backward()\n",
    "        optim_dict[\"C\"].step()\n",
    "        loss_dict[\"C\"] = c_loss.detach().cpu().numpy().item()\n",
    "    \n",
    "    return loss_dict\n",
    "    \n",
    "\n",
    "def test_epoch(data_list, adj_list, te_idx, model_dict):\n",
    "    for m in model_dict:\n",
    "        model_dict[m].eval()\n",
    "    num_view = len(data_list)\n",
    "    ci_list = []\n",
    "    for i in range(num_view):\n",
    "        ci_list.append(model_dict[\"C{:}\".format(i+1)](model_dict[\"E{:}\".format(i+1)](data_list[i],adj_list[i])))\n",
    "    if num_view >= 2:\n",
    "        c = model_dict[\"C\"](ci_list)    \n",
    "    else:\n",
    "        c = ci_list[0]\n",
    "    c = c[te_idx,:]\n",
    "    prob = F.softmax(c, dim=1).data.cpu().numpy()\n",
    "    \n",
    "    return prob\n",
    "\n",
    "\n",
    "def train_test(data_folder, view_list, num_class,\n",
    "               lr_e_pretrain, lr_e, lr_c, \n",
    "               num_epoch_pretrain, num_epoch, adj_param,i):\n",
    "    test_inverval = 50\n",
    "    num_view = len(view_list)\n",
    "    dim_hvcdn = pow(num_class,num_view)\n",
    "    adj_parameter = adj_param\n",
    "    dim_he_list = [400,400,200]\n",
    "    data_tr_list, data_trte_list, trte_idx, labels_trte = prepare_trte_data(data_folder, view_list,i)\n",
    "    labels_tr_tensor = torch.LongTensor(labels_trte[trte_idx[\"tr\"]])\n",
    "    onehot_labels_tr_tensor = one_hot_tensor(labels_tr_tensor, num_class)\n",
    "    sample_weight_tr = cal_sample_weight(labels_trte[trte_idx[\"tr\"]], num_class)\n",
    "    sample_weight_tr = torch.FloatTensor(sample_weight_tr)\n",
    "    if cuda:\n",
    "        labels_tr_tensor = labels_tr_tensor.cuda()\n",
    "        onehot_labels_tr_tensor = onehot_labels_tr_tensor.cuda()\n",
    "        sample_weight_tr = sample_weight_tr.cuda()\n",
    "    adj_tr_list, adj_te_list = gen_trte_adj_mat(data_tr_list, data_trte_list, trte_idx, adj_parameter)\n",
    "    dim_list = [x.shape[1] for x in data_tr_list]\n",
    "    model_dict = init_model_dict(num_view, num_class, dim_list, dim_he_list, dim_hvcdn)\n",
    "    for m in model_dict:\n",
    "        if cuda:\n",
    "            model_dict[m].cuda()\n",
    "    \n",
    "    print(\"\\nPretrain GCNs...\")\n",
    "    optim_dict = init_optim(num_view, model_dict, lr_e_pretrain, lr_c)\n",
    "    for epoch in range(num_epoch_pretrain):\n",
    "        train_epoch(data_tr_list, adj_tr_list, labels_tr_tensor, \n",
    "                    onehot_labels_tr_tensor, sample_weight_tr, model_dict, optim_dict, train_VCDN=False)\n",
    "    print(\"\\nTraining...\")\n",
    "    optim_dict = init_optim(num_view, model_dict, lr_e, lr_c)\n",
    "    for epoch in range(num_epoch+1):\n",
    "        train_epoch(data_tr_list, adj_tr_list, labels_tr_tensor, \n",
    "                    onehot_labels_tr_tensor, sample_weight_tr, model_dict, optim_dict)\n",
    "        if epoch == 2500:      \n",
    "            te_prob = test_epoch(data_trte_list, adj_te_list, trte_idx[\"te\"], model_dict)\n",
    "            acc = accuracy_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1))\n",
    "            f1_w = f1_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1), average='weighted')\n",
    "        #if epoch % test_inverval == 0:\n",
    "            f1_m = f1_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1), average='macro')\n",
    "            print(\"\\nTest: Epoch {:d}\".format(epoch))\n",
    "            if num_class == 2:\n",
    "                print(\"Test ACC: {:.3f}\".format(accuracy_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1))))\n",
    "                print(\"Test F1: {:.3f}\".format(f1_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1))))\n",
    "                print(\"Test AUC: {:.3f}\".format(roc_auc_score(labels_trte[trte_idx[\"te\"]], te_prob[:,1])))\n",
    "            else:\n",
    "                print(\"Test ACC: {:.3f}\".format(accuracy_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1))))\n",
    "                print(\"Test F1 weighted: {:.3f}\".format(f1_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1), average='weighted')))\n",
    "                print(\"Test F1 macro: {:.3f}\".format(f1_score(labels_trte[trte_idx[\"te\"]], te_prob.argmax(1), average='macro')))\n",
    "            print()\n",
    "    return acc, f1_w, f1_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a8d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":  \n",
    "    \n",
    "    i = 0\n",
    "    n_trials = 1000\n",
    "    results = {}\n",
    "    \n",
    "    while i < n_trials:\n",
    "        \n",
    "        data_folder = \"../BRCA\"\n",
    "        view_list = [1,2,3]\n",
    "        num_epoch_pretrain = 500\n",
    "        num_epoch = 2500\n",
    "        \n",
    "        \n",
    "        lr_e_pretrain = 1e-3\n",
    "        lr_e = 5e-4\n",
    "        lr_c = 1e-3\n",
    "        \n",
    "        adj_param = 10\n",
    "        num_class = 5\n",
    "        \n",
    "        acc_r = 0\n",
    "        f1_w_r = 0\n",
    "        f1_m_r = 0\n",
    "    \n",
    "        acc_r, f1_w_r, f1_m_r = train_test(data_folder, view_list, num_class,\n",
    "               lr_e_pretrain, lr_e, lr_c, \n",
    "               num_epoch_pretrain, num_epoch, adj_param, i)\n",
    "        \n",
    "        results[i] = {\"acc\" : acc_r, \"f1_weighted\" : f1_w_r, \"f1_macro\" : f1_m_r}\n",
    "        \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e42ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
