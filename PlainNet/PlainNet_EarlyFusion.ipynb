{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-18T13:35:04.641737Z",
     "iopub.status.busy": "2023-09-18T13:35:04.641381Z",
     "iopub.status.idle": "2023-09-18T13:35:15.245647Z",
     "shell.execute_reply": "2023-09-18T13:35:15.244402Z",
     "shell.execute_reply.started": "2023-09-18T13:35:04.641709Z"
    }
   },
   "outputs": [],
   "source": [
    "#Importing useful libraries\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import optuna\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import  Input, Dense, Dropout, Attention\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T14:17:33.890406Z",
     "iopub.status.busy": "2023-09-18T14:17:33.889148Z",
     "iopub.status.idle": "2023-09-18T14:17:33.896317Z",
     "shell.execute_reply": "2023-09-18T14:17:33.895533Z",
     "shell.execute_reply.started": "2023-09-18T14:17:33.890360Z"
    }
   },
   "outputs": [],
   "source": [
    "#Select which dataset to load\n",
    "dataset = \"rosmap\"\n",
    "\n",
    "#Dataset Loading\n",
    "if  dataset == \"rosmap\":\n",
    "    \n",
    "    path = \"../ROSMAP/\"\n",
    "    #Loading data already early concatenated\n",
    "    rosmap = pd.read_csv(path + \"rosmap_all_omics.csv\", index_col = 0)\n",
    "    r_lab = pd.read_csv(path + \"rosmap_labels.csv\", index_col = 0)\n",
    "    X = rosmap.to_numpy()\n",
    "    y = r_lab\n",
    "    #Loading specific data split\n",
    "    omic1_tr = pd.read_csv(path + \"1_tr.csv\", header = None)\n",
    "    omic1_te = pd.read_csv(path + \"1_te.csv\", header = None)\n",
    "    omic2_tr = pd.read_csv(path + \"2_tr.csv\", header = None)\n",
    "    omic2_te = pd.read_csv(path + \"2_te.csv\", header = None)\n",
    "    omic3_tr = pd.read_csv(path + \"3_tr.csv\", header = None)\n",
    "    omic3_te = pd.read_csv(path + \"3_te.csv\", header = None)\n",
    "    lab_tr = pd.read_csv(path + \"labels_tr.csv\", header = None)\n",
    "    lab_te = pd.read_csv(path + \"labels_te.csv\", header = None)\n",
    "    omic_tr = pd.concat([omic1_tr,omic2_tr], axis = 1)\n",
    "    omic_tr = pd.concat([omic_tr,omic3_tr], axis = 1)\n",
    "    omic_te = pd.concat([omic1_te,omic2_te], axis = 1)\n",
    "    omic_te = pd.concat([omic_te,omic3_te], axis = 1)\n",
    "    num_classes = 2\n",
    "        \n",
    "elif \"brca\": \n",
    "    \n",
    "    path = \"../BRCA/\"\n",
    "    #Loading data already early concatenated\n",
    "    brca = pd.read_csv(path + \"/brca_all_omics.csv\", index_col = 0)\n",
    "    b_lab = pd.read_csv(path + \"/brca_labels.csv\", index_col = 0)\n",
    "    #Loading specific data split\n",
    "    omic1_tr = pd.read_csv(path + \"1_tr.csv\", header = None)\n",
    "    omic1_te = pd.read_csv(path + \"1_te.csv\", header = None)\n",
    "    omic2_tr = pd.read_csv(path + \"2_tr.csv\", header = None)\n",
    "    omic2_te = pd.read_csv(path + \"2_te.csv\", header = None)\n",
    "    omic3_tr = pd.read_csv(path + \"3_tr.csv\", header = None)\n",
    "    omic3_te = pd.read_csv(path + \"3_te.csv\", header = None)\n",
    "    lab_tr = pd.read_csv(path + \"labels_tr.csv\", header = None)\n",
    "    lab_te = pd.read_csv(path + \"labels_te.csv\", header = None)\n",
    "    omic_tr = pd.concat([omic1_tr,omic2_tr], axis = 1)\n",
    "    omic_tr = pd.concat([omic_tr,omic3_tr], axis = 1)\n",
    "    omic_te = pd.concat([omic1_te,omic2_te], axis = 1)\n",
    "    omic_te = pd.concat([omic_te,omic3_te], axis = 1)\n",
    "    X = brca.to_numpy()\n",
    "    y = b_lab\n",
    "    num_classes = 5\n",
    "\n",
    "y = y.to_numpy()\n",
    "y = y.reshape(y.shape[0],)\n",
    "\n",
    "#If random split == 0, uses the author's split\n",
    "random_split = 1\n",
    "\n",
    "\n",
    "#seeds = [30, 300, 3000, 30000, 300000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create 1000 seeds to perform splitting on data\n",
    "seeds = []\n",
    "for i in range(0,1000):\n",
    "    n = random.randint(1,500000)\n",
    "    seeds.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-18T15:03:27.210751Z",
     "iopub.status.busy": "2023-09-18T15:03:27.210341Z",
     "iopub.status.idle": "2023-09-18T15:03:45.611723Z",
     "shell.execute_reply": "2023-09-18T15:03:45.610531Z",
     "shell.execute_reply.started": "2023-09-18T15:03:27.210716Z"
    }
   },
   "outputs": [],
   "source": [
    "if dataset == \"rosmap\":    \n",
    "    #Binary Classification\n",
    "\n",
    "    acc = []\n",
    "    auc = []\n",
    "    f1 = []\n",
    "\n",
    "    #Hyperparameters for ROSMAP\n",
    "    \n",
    "    drop_rate = 0.3    # 0.5\n",
    "    drop_rate_out = 0.3\n",
    "    neuron_dense1 = 2000  #1000\n",
    "    neuron_dense2 = 40  #160\n",
    "    neuron_dense3 = 4  #8\n",
    "    activation_dense = 'tanh'  #relu\n",
    "    activation_output = 'sigmoid'\n",
    "    num_epochs = 100\n",
    "    es_patience = 15\n",
    "    batch = 64\n",
    "    val_split = 0.1\n",
    "    test_split = 0.2\n",
    "    i = 0\n",
    "\n",
    "    for seed in seeds:\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print(\"___________________________\" + str(i) + \"_________________\")\n",
    "            \n",
    "        if random_split:\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_split, \\\n",
    "                                                            random_state=seed, stratify = y)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            X_train = omic_tr.to_numpy()\n",
    "            X_test = omic_te.to_numpy()\n",
    "            y_train = lab_tr.to_numpy().reshape(lab_tr.shape[0],)\n",
    "            y_test = lab_te.to_numpy().reshape(lab_te.shape[0],)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        #Simple Network Architecture\n",
    "        \n",
    "        input_layer = Input(shape=(X_train.shape[1],))\n",
    "        attention = Attention()([input_layer, input_layer])\n",
    "        x = Dropout(drop_rate)(attention)\n",
    "        x = Dense(neuron_dense1, activation = activation_dense)(x)\n",
    "        x = Dropout(drop_rate)(x)\n",
    "        x = Dense(neuron_dense2, activation = activation_dense)(x)\n",
    "        x = Dropout(drop_rate_out)(x)\n",
    "        x = Dense(neuron_dense3, activation = activation_dense)(x)\n",
    "        output_layer = Dense(1, activation = activation_output)(x)\n",
    "\n",
    "\n",
    "        model = Model(inputs = input_layer, outputs = output_layer)\n",
    "\n",
    "        model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = es_patience)\n",
    "        history = model.fit(X_train, y_train, epochs = num_epochs, batch_size = batch, \\\n",
    "                  callbacks = [callback], validation_split = val_split, verbose = 0)\n",
    "\n",
    "        y_pred_ = model.predict(X_test)\n",
    "        y_pred = np.round(y_pred_)\n",
    "        y_pred = y_pred.astype(int)\n",
    "\n",
    "        acc.append(accuracy_score(y_test, y_pred))\n",
    "        auc.append(roc_auc_score(y_test, y_pred_))\n",
    "        f1.append(f1_score(y_test, y_pred))\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    print(\"ACC:\", format(np.mean(acc), \".4f\"), format(np.std(acc), \".4f\"))\n",
    "    print(\"AUC:\", format(np.mean(auc), \".4f\"), format(np.std(auc), \".4f\"))\n",
    "    print(\"F1:\", format(np.mean(f1), \".4f\"), format(np.std(f1), \".4f\"))\n",
    "    \n",
    "else:\n",
    "    \n",
    "    #Multiclass classification\n",
    "    \n",
    "    acc = []\n",
    "    f1m = []\n",
    "    f1w = []\n",
    "    \n",
    "    #Hyperparameters for BRCA\n",
    "    \n",
    "    drop_rate = 0.3\n",
    "    drop_rate_out = 0.3\n",
    "    neuron_dense1 = 1000\n",
    "    neuron_dense2 = 160\n",
    "    neuron_dense3 = 8\n",
    "    activation_dense = 'relu'\n",
    "    activation_output = 'softmax'\n",
    "    num_epochs = 100\n",
    "    es_patience = 50\n",
    "    batch = 64\n",
    "    val_split = 0.1\n",
    "    test_split = 0.2\n",
    "        \n",
    "    for seed in seeds:\n",
    "\n",
    "        if random_split:\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_split, \\\n",
    "                                                            random_state=seed, stratify = y)\n",
    "        \n",
    "        else:\n",
    "            X_train = omic_tr.to_numpy()\n",
    "            X_test = omic_te.to_numpy()\n",
    "            y_train = lab_tr.to_numpy().reshape(lab_tr.shape[0],)\n",
    "            y_test = lab_te.to_numpy().reshape(lab_te.shape[0],)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        input_layer = Input(shape=(X_train.shape[1],))\n",
    "        attention = Attention()([input_layer, input_layer])\n",
    "        x = Dropout(drop_rate)(attention)\n",
    "        x = Dense(neuron_dense1, activation = activation_dense)(x)\n",
    "        x = Dropout(drop_rate)(x)\n",
    "        x = Dense(neuron_dense2, activation = activation_dense)(x)\n",
    "        x = Dropout(drop_rate_out)(x)\n",
    "        x = Dense(neuron_dense3, activation = activation_dense)(x)\n",
    "        output_layer = Dense(num_classes, activation = activation_output)(x)\n",
    "\n",
    "        model = Model(inputs = input_layer, outputs = output_layer)\n",
    "\n",
    "        model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = es_patience)\n",
    "        class_weights = class_weight.compute_class_weight(class_weight = 'balanced', \\\n",
    "                                                          classes = np.unique(y_train), y = y_train)\n",
    "        model.fit(X_train, y_train, epochs = num_epochs,  batch_size = batch, \\\n",
    "                  callbacks=[callback], validation_split = val_split, \\\n",
    "                  class_weight=dict(enumerate(class_weights)),\\\n",
    "                  verbose = 0)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        acc.append(accuracy_score(y_test, y_pred_classes))\n",
    "        f1w.append(f1_score(y_test, y_pred_classes, average = 'weighted'))\n",
    "        f1m.append(f1_score(y_test, y_pred_classes, average = 'macro'))\n",
    "\n",
    "    print(\"ACC:\", format(np.mean(acc), \".4f\"), format(np.std(acc), \".4f\"))\n",
    "    print(\"F1M:\", format(np.mean(f1m), \".4f\"), format(np.std(f1m), \".4f\"))\n",
    "    print(\"F1W:\", format(np.mean(f1w), \".4f\"), format(np.std(f1w), \".4f\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving Results\n",
    "if dataset == \"rosmap\":\n",
    "    dic = {\"Acc\": acc, \"Auc\": auc, \"F1\" : f1}\n",
    "\n",
    "    with open('rosmap_att_early_1000.pickle', 'wb') as handle:\n",
    "        pickle.dump(dic, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "elif \"brca\":\n",
    "    dic = {\"Acc\": acc, \"F1M\": f1m, \"F1W\" : f1w}\n",
    "\n",
    "    with open('brca_att_early_1000.pickle', 'wb') as handle:\n",
    "        pickle.dump(dic, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
